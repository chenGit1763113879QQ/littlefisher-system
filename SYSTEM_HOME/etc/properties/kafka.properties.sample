################################### Pruducer Settings #####################################################
# kafka broker的ip和host，可以多个
producer_bootstrap_servers=192.168.229.128:9092
# ack模式
producer_acks=all
# 用户随意指定，但是不能重复，主要用于跟踪记录消息
producer_client_id=localhost
# 重试次数
producer_retries=30
# Producer会尝试去把发往同一个Partition的多个Requests进行合并，
# batch.size指明了一次Batch合并后Requests总大小的上限。如果这个值设置的太小，可能会导致所有的Request都不进行Batch
producer_batch_size=16384
# Producer默认会把两次发送时间间隔内收集到的所有Requests进行一次聚合然后再发送，以此提高吞吐量，
# 而linger.ms则更进一步，这个参数为每次发送增加一些delay，以此来聚合更多的Message
producer_linger_ms=50
# 在Producer端用来存放尚未发送出去的Message的缓冲区大小。
# 缓冲区满了之后可以选择阻塞发送或抛出异常，由block.on.buffer.full的配置来决定
producer_buffer_memory=33554432
# Broker等待ack的超时时间，若等待时间超过此值，会返回客户端错误信息。
producer_request_timeout_ms=10000
# 每次重新连接的间隔时间
producer_reconnect_backoff_ms=20000
# 每次失败后的间隔时间
producer_retry_backoff_ms=20000
# Key的序列化类
producer_key_serializer=org.apache.kafka.common.serialization.StringSerializer
# Value的序列化类
producer_value_serializer=org.apache.kafka.common.serialization.StringSerializer

################################### Consumer Settings #####################################################
# kafka broker的ip和host，可以多个
consumer_bootstrap_servers=192.168.229.128:9092
# 决定该Consumer归属的唯一组ID，By setting the same group id multiple processes indicate that they are all part of the same consumer group.
consumer_group_id=0
# 设置是否可以自动提交
consumer_enable_auto_commit=true
# 自动提交的时间间隔
consumer_auto_commit_interval_ms=1000
# session超时时间
consumer_session_timeout_ms=15000
# Key的序列化类
consumer_key_deserializer=org.apache.kafka.common.serialization.StringDeserializer
# Value的序列化类
consumer_value_deserializer=org.apache.kafka.common.serialization.StringDeserializer